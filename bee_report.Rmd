---
title: "Bistader"
subtitle: "62527 Big data E20"
author: "Armandas Rokas(s185144)"
date: "11/09 2020"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
---
\definecolor{h}{HTML}{FFFF66}
\pagenumbering{gobble} 


\pagebreak
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("bee_my_functions.R")
library(dplyr)
library(forecast)
library(Hmisc)
library(caret) 
setwd("/home/arm/Projects/bigdata_bees")
```
\pagebreak
\pagenumbering{arabic} 

\colorbox{h}{TODO}
- Problemstilling i startten, hvad er formål ved projekten
- Kapitel nummer
- Figur nummer osv.

## Introduktion(dette måske lidt mere Data beskrivelse)
Dette rapport beskriver databehandling af data fra et bistade.  Dataen samles via Raspbarry Pi, som er tilknyttet til forskellige sensorer, som måler vægten, fugtighed, lys osv. (hele listen af variabler kan man se i [Variabler](#variabler) afsnit), og gemmes både lokalt på SQLite databasen og sendes til HiveTool.net platformen. 


## Import af data
Der blev valgt at bruge SQLite til at indlæse dataen, da det er lidt svært at få fat i dataen på HiveTool.net, især hvis man skal bruge en lang tidsperiode. Så der blev skrevet en `import_hive_data` funktion, som indlæser dataen fra SQLite (Koden af funktionen kan findes i [Bilag B](#bilab_B)). 


## Data beskrivelse
Observationer fra bistadet bliver taget hver 5. minut og der er i alt 105064 observationer ([Bilag A](#bilag_A)). Dataen er dog ikke helt konsistent, da der er nogle huller i datasættet, hvor der mangler målinger, og der er nogle målinger, som har forkerte værdier. Dataen går helt tilabge til 2018-03-07, men den bliver mere og mere inkonsistente jo mere i fortiden man går, så derfor blev der valgt at tage udgangspunkt i et års data, dvs. fra 2019-09-01 til 2020-09-01.


```{r include=FALSE}
hive_data <- import_hive_data(from = "'2019-09-01 00:00:00'", to="'2020-09-01 00:00:00'", raw=TRUE)
```



### Variabler {#variabler}

Der er i alt 43 variabler i datasættet, men ud fra opsummering af alle variabler i datasættet i [Bilag A](#bilag_A) kan man konstatere at disse variabler kun er i brug og relevente: `hive_observation_time_local`, `hive_weight_kgs`, `hive_temp_c`, `hive_humidity`, `ambient_temp_c`,
`ambient_humidity`og `ambient_luminance`. Nedenfor opsummering af disse variabler:


```{r}
des <- Hmisc::describe(hive_data)
des$hive_observation_time_local$extremes <- NULL
print(des)
```

```{r echo=FALSE}
#summary(hive_data$hive_observation_time_local)
#summary(hive_data$hive_weight_kgs)
#summary(hive_data$hive_temp_c)
#summary(hive_data$hive_humidity)
#summary(hive_data$ambient_temp_c)
#summary(hive_data$ambient_humidity)
#summary(hive_data$ambient_luminance)
```

\pagebreak

### Vægten
Vægten er den centrale variable i datasættet. For eksempel nedenfor kan man se en vægtudvikling fra i perioden fra 2019-09-01 til 2020-09-01, hvor man kan se tydeligt to sæsoner. Om vinteren vægten bliver gradvis mindre, fordi biene spiser føder, og om sommer trakker nektar ind i et bistade. 

```{r echo=FALSE}
hive_data <- import_hive_data(from = "'2019-09-01 00:00:00'", to="'2020-09-01 00:00:00'")
plot_time_weight(hive_data) 
```

### Eksternal vejr data

til at fylde op datasæt med relavent vejr data blev der benyttet https://www.dmi.dk/vejrarkiv/ hjemsside til at får nedbør,  vindhastighed, tørkeindex, luftfugtighed, lufttryk, solskin timer. Nedenfor kan man see opsummering af en eksampel af vejr data i juni måned i 2020: 



```{r}
weather_data_furesoe_jun <- read.table(file="data/furesø-kommune-juni-2020.csv", sep="," ,header = TRUE)
weather_data_furesoe_jun$dt <- as.Date(weather_data_furesoe_jun$dt)
#Hmisc::describe(weather_data_furesoe_jun)
plot.ts(weather_data_furesoe_jun[-1])

```


\colorbox{h}{Kan det være, at jeg får en fejl, når jeg laver en modellen, fordi data er meget skewed? }

\colorbox{h}{Jeg har også prøvet at normalisere, men jeg får det samme...}

\colorbox{h}{Hvad med, hvis jeg definerer grænseværdier selv. Dvs om det regnet eller det var solen hele dag. }

```{R , fig.height=8, fig.width=8}
par(mfrow=c(3,2))
hist(weather_data_furesoe_jun$precipitation, main="precipitation")
hist(weather_data_furesoe_jun$wind, main="wind")
hist(weather_data_furesoe_jun$drought, main="drought")
hist(weather_data_furesoe_jun$humidity, main="humidity")
hist(weather_data_furesoe_jun$pressure, main="pressure")
hist(weather_data_furesoe_jun$sun, main="sun")
```

## Dataoprensning

Der er flere årsager til at det er svært at aflæse en eksakt tilvækst af vægten. De mulige årsager kunne være:

  - Manuelt indgreb
  - Nedbør 
  - Biernes daglig rutine
  
Disse er beskrevet videre i afsnittet udtaget nedbør, da dette giver minimalt støj og der er ikke umiddelbart behov til at tage hensyn til det. 
 
<!-- https://en.wikipedia.org/wiki/Data_cleansing --> 

### Manuelle indgreb 
Manuelle indgreb på bistadet medfører de største udsving i vægten, men som ikke forårsagers af bierne, så disse skulle fjernes før man kunne påbegynde noget andet. Eksempler på manuelle indgreb kunne være:

 - Påsætte/fjerne magasin
 - Andre mindre manipulationer

De fleste manual indgreb følge efter afbrydelser i timestamps. Det kan forklares med at en biavler slukker optagelse af målinger, når biavlen laver et manualt indgreb, men når han tænder optagelsen, laver den en stor udsving i vægten i en eller anden retning i for hold hvad han fik lavet. (Bemærk, man behøver ikke at tage hensyn til det manglende timestamps, fordi alt videre analyse er gennemført på middnats værdier, som ikke er manglende).  

Så derfor blev der startede med at finde deltaerne mellem vægtene før arbrydelser i timestmaps og efter, dvs. huler i datasættet. En liste over det kan man se nedenfor:
 
```{r echo=FALSE}


hive_data <- hive_data %>%  mutate(timestamp_delta = hive_observation_time_local -
  dplyr::lag(hive_observation_time_local)) %>% 
  mutate(timestamp_delta = ifelse(is.na(timestamp_delta), 0, timestamp_delta))

hive_data <- hive_data %>%  mutate(weight_delta = hive_weight_kgs -
  dplyr::lag(hive_weight_kgs)) %>%
  mutate(weight_delta = ifelse(is.na(weight_delta), 0, weight_delta))

hive_data[which(hive_data[,"timestamp_delta"] > 7 & abs(hive_data[,"weight_delta"]) > 2 ), 
          c("hive_observation_time_local", "weight_delta")]
```

- Man kan se at ikke alle huler følger efter en stor udsving i vægten, men det kunne være en mulig løsning til at fjerne alligevel alle, hvis man har lyst til at automatisere databehandling. Den anden mulighed, som er ønsket af projektstilleren at have mulighed at definere selv perioder, som skal ignoreres.  
- For at visualisere problemet bedre blev der valgt at plotte vægten videre omkring `2020-05-28 12:25:01`, hvor vægten har øget med `3.49`, fordi der blev sat en nye magasin ind. Nedenfor er grafen over vægten omkring dette tidspunkt.

```{r echo=FALSE}
hive_data <- import_hive_data(from = "'2020-05-24 00:00:00'", to="'2020-06-01 00:00:00'")
plot_time_weight(hive_data)
```

\pagebreak

- Så der blev skrevet en lille funktion til at udligne disse manuelle indgreb (hele koden af funktionen kan findes i [Bilag B](#bilag_B)). Funktionen tager imod bistader data og perioder, som skal udlignes. Den returnere behandlet bistade data. Nedenfor kan man se to grafer, til venstre er der en graf med den oprindelige data og til højre er der en graf med den behandlede data, dvs. udlignede manuelle indgreb. 

```{R echo=FALSE}
 hive_data <- import_hive_data(from = "'2020-05-01 00:00:00'", to="'2020-09-01 00:00:00'")
  par(mfrow=c(1,2))
  plot_time_weight(hive_data, title="Den oprindelige data")
  
  

  periods_to_remove <- read.table(file="data/stade1_period_to_ignore_manipulate.csv", sep=",", header = TRUE)
  hive_data <- manipulate_weight_deltas(hive_data=hive_data, periods=periods_to_remove)
  
  
  plot_time_weight(hive_data, title="Den behandlede data")

```

\pagebreak
 
### Midnats vægt

<!-- måske samle vægt og temperatur under et "Daglig værider" -->

Den anden ting, som gør det svært at aflæse den ægte vægt tilvækst pr. dag, er at der alt for mange datapunkter, hvor der er målinger hvert 5. minut. Bierne følger den daglige rutine. Det flyver ud om morgen, indsamler nektar i løbet af dagen, om natten fordamper den. Det medfører at vægten svinger op og ned i løbet af dagen og for at se den ægte vægt tilvækst pr. dag er det bedst at kigge på midnatsværdier. Så der blev skrevet endnu en funktion, som trækker ud midnatsværdier (hele koden kan findes i [Bilag B](#bilag_B)). Nedenfor er der to grafer. Til venstre er der alle data punkter, dvs. hvert 5. minut. Til højre er der kun midnatsværdier. Man kan se at det er nemmere aflæse grafen kun med midnatsværdier især i august måned, hvor vægten svinger mest i løbet af dagen. 
- Det var også nødt til at skubbe en dag tilbage. Dvs. den skal vise en f.eks. en vægt måling som tage 2020-05-23 00:00:01 viser faktisk vægt tilvækst i den 2020-05-22, so det vil være ukorrekt at den blev stående i 2020-05-23, dvs. det vil ikke passe med andre målinger som for eksampel maksimale temperatur , da  vi har lyst til at finde ud vægt tilvækst i forhold til den forudgående dags maksimale temperatur hvis vi tager f.eks. 2020-05-20 00:00:01 vægt, så vi skal bruge den højeste tempratur dagen før, som var på tidspunt: 2020-05-19 15:55:01  dvs med det tempratur var dette tilvækst.. Defor alle vægt vædier er skubbet bagud med funktionen `lead`

```{R echo=FALSE}
  hive_data <- import_hive_data(from = "'2020-05-01 00:00:00'", to="'2020-09-01 00:00:00'")
  periods_to_remove <- read.table(file="data/stade1_period_to_ignore_manipulate.csv", sep=",", header = TRUE)
  hive_data <- manipulate_weight_deltas(hive_data=hive_data, periods=periods_to_remove)
  par(mfrow=c(1,2))
  plot_time_weight(hive_data, title="Alle datapunkter")
  hive_data <- extract_midnight_weights(hive_data)
  plot_time_weight(hive_data, title="Kun midnatsværdier")
```

### Middags temperatur

Ligesom kan man få mest indsigt i data ved at kigge på midnatsvægt, så er det bedst at kigge på den højeste temperatur på dagen, da det mest afsåejler bienerne bevægelse. 
Projektstiller har sagt at det bedste at bruge middags værider for at se udvikling. 
Men man kan iike bruge temp midnat. Projekt sitllerende forslået at bruge middags værider, men det var lidt svært at trakke dem ud at datasæt, pga. manglende data og ulige tidstempler. Så der blev valgt at bruge den højeste døgn værdi med midnatsvægt.  

- Efter der blev fandt den højest tempratur på dagen, blev der nødt til at "lag" tempratur en dag bagud. Det kan forklares, at . Dvs.

\pagebreak

## Dataanalyze


### Sammenligning af bistader
I dette afsnit skal der sammenlignes to bistader fra den samen have (videre i afsnit bliver det kaldt Bistade1, Bistade3). Formålet med sammenligned at vudere om den anden familie præstere bedre end den anden og forudse sygdomme. Nedenfor kan man se to grafer af bistadet, som er behandlede for manuelle indgreb og kun midnatsværdier jf. Oprensning afsnit.  


```{R echo=FALSE}
# Hive 1
hive1 <- import_hive_data(from = "'2020-05-01 00:00:00'", to="'2020-09-01 00:00:00'")
periods_to_remove1 <- read.table(file="data/stade1_period_to_ignore_manipulate.csv", sep=",", header = TRUE)
hive1 <- manipulate_weight_deltas(hive_data=hive1, periods=periods_to_remove1)
hive1 <- extract_midnight_weights(hive1)

# Hive 3
hive3 <- import_hive_data_csv("data/FHA_Stade3_MAJ_SEP")
periods_to_remove3 <- read.table(file="data/stade3_period_to_ignore.csv", sep=",", header = TRUE)
hive3 <- manipulate_weight_deltas(hive_data=hive3, periods=periods_to_remove3)
hive3 <- extract_midnight_weights(hive3)


# Plot
min <- as.Date(head(hive1, 1)[,"hive_observation_time_local"])
max <- as.Date(tail(hive1, 1)[,"hive_observation_time_local"])
par(mar = c(5, 5, 3, 5))
plot(hive3$hive_observation_time_local, hive3$hive_weight_kgs, type ="l", ylab = "Vægt",
     main ="Vægtudvikling på bistade1 og bistade3", xlab = paste("Tid fra", min, "til", max, sep= " "),
     col = "blue")
lines(hive1$hive_observation_time_local, hive1$hive_weight_kgs,col="red")
#par(new = TRUE)
#plot(hive3$hive_observation_time_local, hive3$hive_weight_kgs, type = "l", xaxt = "n", yaxt = "n",
#     ylab = "", xlab = "", col = "red") # , lty = 2
#axis(side = 4)
#mtext("Temperatur", side = 4, line = 3)
legend("topleft", c("Bistade1", "Bistade3"),
       col = c("red", "blue"), lty = c(1, 1))
```

#### Den daglige vægttilvækst
For at gøre det nemmere at sammenligne bistader, blev der taget de daglige vægttvækst af disse bistader. Gennemsnit af de dagligt vægttilvækst for de respektive bistader er $\mu_1=0.1598374$(Bistade1) og $\mu_3=0.2188468$(Bistade3).

```{r include=FALSE}
hive1 <- hive1 %>%  mutate(daily_weight_delta = hive_weight_kgs -
  dplyr::lag(hive_weight_kgs)) %>%
  mutate(daily_weight_delta = ifelse(is.na(daily_weight_delta), 0, daily_weight_delta))

hive3 <- hive3 %>%  mutate(daily_weight_delta = hive_weight_kgs -
  dplyr::lag(hive_weight_kgs)) %>%
  mutate(daily_weight_delta = ifelse(is.na(daily_weight_delta), 0, daily_weight_delta))
```

```{r}

mean(hive1$daily_weight_delta)
mean(hive3$daily_weight_delta)

```



```{R echo=FALSE}

plot(hive1$hive_observation_time_local, hive1$daily_weight_delta, type="h",main="Daglig vægttilvækst", ylab="Vægt", xlab="", col="red")
lines(hive3$hive_observation_time_local, hive3$daily_weight_delta,col="blue", lwd = 0.2, , lty=2, type="l")
legend("topleft", c("Bistade1", "Bistade3"),
       col = c("red", "blue"), lty = c(1, 1))
```

#### Hypotesetest.
 Umiddelbart kan man se, at bistade 3 har lidt højere gennemsnit, men er det nok at konstatere forskellen mellem disse stader? For at undersøge det blev der udført et hypotesetest. 


$$
\begin{aligned}
H_{0} \ : \ \mu_{1}= \mu_{3} \equiv \mu_{1}-\mu_{3}= 0 \\
H_{1}\ : \ \mu_{1} \ne \mu_{3} \equiv \mu_{1}-\mu_{3}\ne 0
\end{aligned}
$$

#### "Welch Two Sample t-test" 
Nedenfor **kan der ikke konstateres en signifikant forskel i den daglige vægttilvækst mellem Bistade1 og Bistade3**, fordi $\text{p-value}$ (sandsynlighed at vi har fået denne forskel tilfældigt) er ret stor 0.5763  og 95% konfidensinterval inkluderer 0. Dvs. vi ikke kan afvise $H_0$, sem er, at de daglige vægttilvækst er ens. 

```{R}
t.test(hive1$daily_weight_delta, hive3$daily_weight_delta)
```
#### Konklusion på sammenligning
Selv om der ikke kunne lade sig gøres at bevise signifikant forskellen på bistader ved at bruge t.test, er den forskellen som man kan sige på grafer er nok til biavlen til at konkludere, at der er en tydeligt eksampel på at bifamilier er forskellige, da stade3 producerer mest honning, og derfor ville han vælge Bistade3, som "mor" til en evt ny familie.  

\pagebreak

## Forudsigelse af vægten i en vinterperiode


#### Formål 
Den første formål er, at det er ret vigtigt for biavlen at overvåge om bierne har nok foder i en vinter periode. Det vil sige, at vægten falder gradvis i løbet af vinteren, men den skal ikke falde under en vist niveau, og biavlen skal gribe ind, hvis den gør. Så det kunne være en fordel til biavlen, at han kunne forudsige, hvornår den falder under dette niveau, så biavlen kunne fylde foderdepoter op. Hvis vi f.eks. tager Bistade1, så ligger dens minimumvægt på 15kg, da magasin, tavler og bier vejer omkring 12 kg. 
Den anden formål kunne være at forudsige om familien har det godt om vinteren. Familien er god stand, hvis vægten falder konstant og som forventet, så det betyder at familien forbruger foder, men hvis vægten stopper med at falde, så det kan være en tegn, at familien er syg eller i det værste tilfælde uddødet.   



#### Modellen
Der blev benyttet `ets` funktion i `forecast` pakke til at lave en modellen, hvor der blev givet daglige vægtværdier fra 2019-11-01 til 2020-03-01. Denne modellen blev brugt i `forecast` funktionen til at forudsige vægten i hele marts måned. På figuren nedenfor kan man se de forudsagtede værdier. En blå linje betyder "Point Forecast", den mørke gråzone markerer 80% konfidensintervall, og den lyse gråzone markerer 95% konfidensinterval. 

#### Backtesting 
Der blev også lavet en backtesting, fordi vi kender jo de empiriske værdier for marts måned, så disse også blev plottet  på grafen, og man må sige at modellen blev opsat ret korrekt, da alle empiriske værdier ligger ind i 95% konfidensinterval interval. 


```{R include=FALSE}
hive1_winter <- import_hive_data(from = "'2019-11-01 00:00:00'", to="'2020-03-01 00:00:00'")
```

```{R echo=FALSE}


hive1_winter <- extract_midnight_weights(hive1_winter)
#plot_time_weight(hive1_winter)

# Create timeseries object
hive1_winter_weights <- hive1_winter$hive_weight_kgs
thive1 <- ts(hive1_winter_weights, frequency=365, start=c(2019,305))

# Create exponential forecasting model
fit <- ets(thive1)
forecast <- forecast(fit,31)
plot(forecast, ylab = "Vægt", xaxt="n", col="red", main="Forudsigelse af vægtudvikling på Bistade1")

# Find time for ploting
hive1_winter$timeseries <- time(thive1) 
localtime_timeseries <- hive1_winter[, c("hive_observation_time_local", "timeseries")]

tsp <- attributes(thive1)$tsp

df_forecast <-data.frame(forecast)
df_forecast$times <- row.names(df_forecast)

# Plot forecast
axis(1, at = c(tsp[1],2019.915 , 2020.0, 2020.085, 2020.165 , as.numeric(tail(df_forecast$times,1))), 
     labels = c("2019-11", "2019-12" , "2020-01", "2020-02","2020-03" ,"2020-04"))




hive1_marts <- import_hive_data(from = "'2020-02-29 00:00:00'", to="'2020-03-31 00:00:00'")
periods_to_remove <- read.table(file="data/stade1_period_to_ignore_manipulate.csv", sep=",", header = TRUE)
hive1_marts <- manipulate_weight_deltas(hive_data=hive1_marts, periods=periods_to_remove)
hive1_marts <- extract_midnight_weights(hive1_marts)
thive1_marts <- ts(hive1_marts$hive_weight_kgs, frequency=366, start=c(2020,61))
lines(thive1_marts, col="red")

legend("topright", c("Empirisk", "Forudsigelse"),
       col = c("red", "lightblue"), lty = c(1,1), lwd=c(1,2))
 
 #seq(tsp[1], as.numeric(tail(df_forecast$times,1)), along = thive1)
#axis(1, at = seq(tsp[1], as.numeric(tail(df_forecast$times,1)),by=0.2), 
 #    labels = format(hive1_winter$hive_observation_time_local, "%Y-%m-%d"))


#hive_snow <- import_hive_data(from = "'2020-03-28 00:00:00'", to="'2020-04-01 00:00:00'")

```

## Forudsigelse af træk ved at bruge klassificering

 Træk er når bierne henter nektar fra blomsterne, hvilket medfører at bistadets vægten stiger. Hvis vægten ikke stiger, så den plejer at falde gradvis, fordi bierne begynder at spise det, som blev indsamlet. Så i denne sektion vil jeg prøve at forudsige om bierne trækker ved at benytte lufttempratur. Formålet ved det kunne være bl.a. at give en "Early Warning" til biavlen, når biene skulle trækker i forhold til verjet, men vægten faktisk faldet, hvilket kan være en tegn på at der er noget galt med bifamilien.  
 

 

### Forberedese af data

Der blev udført disse forberedelse på dataen til at klargøre daten specifikt til klassificering: 

- Vægttilvæksten, som oprindeligt var kvantitativ variabel, blev lavet om til kvalitative variablel. Vægttilvæksten blev opdelt i to kategorier, UP og DOWN. UP er når vægtilvæksten er positiv og DOWN er når vægttilvæksten er negativ. 
- Der blev valgt at benytte data kun fra juni måned, fordi biene trækker kun, når der er nektar dvs. i slutning af foråret og i starten af sommeren, så derfor vil det ikke give mening at inkludere måneder, hvor der ikke sker noget træk.
- Og sidst såfremt er dataen kun fra 2019 og 2020 , så benyttes der 2020 juni måned til at lave modellen og 2019 juni måned til at validere modellen. 

https://da.bccrwp.org/compare/difference-between-categorical-and-quantitative-data/

Disse forberedelser kan man se i R kode nedenunder. Valideringsdatasættet blev behandlet på samme måde.

```{r}
# Prepare train data
hive_data_2020_jun.train <- import_hive_data_daily(from = "'2020-06-01 00:00:00'",
                                                   to="'2020-07-01 00:00:00'")
hive_data_2020_jun.train <- hive_data_2020_jun.train %>%  mutate(weight_delta = 
                hive_weight_kgs_daily - dplyr::lag(hive_weight_kgs_daily)) %>%
                mutate(weight_delta = ifelse(is.na(weight_delta), 0, weight_delta))
# weightdelta of the first day could not be calculated, 
# because the prior day is not available in the current fetch dataset, 
# so the weight delta is calculated and inserted manually. 
hive_data_2020_jun.train[1,"weight_delta"] <- 0.81 
hive_data_2020_jun.train <- select(hive_data_2020_jun.train, !hive_weight_kgs_daily)
hive_data_2020_jun.train <- hive_data_2020_jun.train %>%
  mutate(weight_delta_direction = ifelse(weight_delta<0, "DOWN", "UP"))
hive_data_2020_jun.train <- select(hive_data_2020_jun.train, !weight_delta)
hive_data_2020_jun.train <- select(hive_data_2020_jun.train, !dt)
hive_data_2020_jun.train$weight_delta_direction <- factor(hive_data_2020_jun.train$weight_delta_direction) 
```

```{r echo=FALSE}
# Prepare validate data
hive_data_2019_jun.validate <- import_hive_data_daily(from = "'2019-06-01 00:00:00'", to="'2019-07-01 00:00:00'")
hive_data_2019_jun.validate <- hive_data_2019_jun.validate %>%  mutate(weight_delta = hive_weight_kgs_daily - dplyr::lag(hive_weight_kgs_daily)) %>%
  mutate(weight_delta = ifelse(is.na(weight_delta), 0, weight_delta))
hive_data_2019_jun.validate[1,"weight_delta"] <- 0.12

hive_data_2019_jun.validate <- select(hive_data_2019_jun.validate, !hive_weight_kgs_daily)

hive_data_2019_jun.validate <- hive_data_2019_jun.validate %>%
  mutate(weight_delta_direction =  ifelse(weight_delta<0, "DOWN", "UP"))

hive_data_2019_jun.validate <- select(hive_data_2019_jun.validate, !weight_delta)
hive_data_2019_jun.validate <- select(hive_data_2019_jun.validate, !dt)

hive_data_2019_jun.validate$weight_delta_direction <-
  
  factor(hive_data_2019_jun.validate$weight_delta_direction) 

```


#### Modellen

- Der blev benyttet "Logistic regression" til at lave modellen, hvor der bruges `glm` function. Fra en opsummering nedenfor kan vi konkludere, at https://www.guru99.com/r-generalized-linear-model.html
- https://www.datacamp.com/community/tutorials/logistic-regression-R

```{r }
set.seed(12345)  
model <- train(weight_delta_direction~ambient_temp_c_day_max, data = hive_data_2020_jun.train,   
                 method = "glm",  
                 trControl = trainControl(method = "cv",number = 5)  )
summary(model)
```

Som man kan se fra modelberksivelsen ovenfor. Beskrive parameter, p value


- Hvad betyder Estimate std. in glm???

\colorbox{h}{Jeg kan ikke lige overskue, hvad betyder coefficients her?}

\colorbox{h}{Dvs. i linær regression, hvis vi øger med så meget predictor variable, så}

\colorbox{h}{So vil det øge med så meget outcome. Men hvad med her?}

"coefficients that do differs from zero at the p<.10 level. "

#### Validering

kk

```{r }
prob <- predict(model, hive_data_2019_jun.validate)
logit.perf <- table(hive_data_2019_jun.validate$weight_delta_direction, prob, dnn=c("Actual", "Predicted"))
logit.perf
```




- En fejl, hvis jeg bruger alle variabler
- Er der nok med en variablet med til modellen?
- Hvorfor weight_delta og hive_weight_kgs har så lille correlation?

```
        Predicted
Actual DOWN UP
  DOWN    6  4
  UP      3 17
```
- Dvs når vi forudsiger at vægten skulle gå UP, men det gik faktisk DOWN, så det kan betyde at der er problem med familien. 
- det var kun 4 der er farlig i dette. Som var predicted UP men var actual DOWN. Dvs. der kunne man få forket "Early warning", som man ikke skal reagere til.


- "Accuracy and Kappa These are the default metrics used to evaluate algorithms on binary and multi-class classification datasets in caret." https://machinelearningmastery.com/machine-learning-evaluation-metrics-in-r/



- Vi kan se, , at modellen forudsat 23 rigtigt ud af 30 dage. da der bruges validerings data fra 2019 july måned.  hvis vi bruger modellen til at forudse vægtændring af dataen fra 2019 July måned
- Der blev brugt bl.a. en "5 fold cross validation" til at estimere, hvor præcist modellen vil estimere i fremtiden. Fra 5-cross validation, vi kan see at modellen har 0.8 nøjagtighed, som er lidt større end resultater fra ved at bruge et års tidlegere data, hvor modellen forudsat 23 rigtigt ud af 30, hivlket giver ca. 0.76 nøjagtighed.

\pagebreak

## Konklusion


\pagebreak

## Bilag
 
### Bilag A: Opsummering af alle variabler i datasættet {#bilag_A}

```{r include=FALSE}
hive_data <- import_hive_data(from = "'2019-09-01 00:00:00'", to="'2020-09-01 00:00:00'", raw=TRUE, all=TRUE)
#str(hive_data)
#summary(hive_data)
```


```{r}
Hmisc::describe(hive_data)
```

### Bilag B: Mine funktioner{#bilag_B} 
```R
import_hive_data <- function(from, to){
  library(DBI)
  con <- dbConnect(RSQLite::SQLite(), "data/stade1.db")
  table_name <- dbListTables(con)
  fields <- dbListFields(con, table_name)
  select_period_with_intervention_query <- paste("SELECT * from", table_name, "WHERE hive_observation_time_local > ",from," AND 
                        hive_observation_time_local < ", to, sep=" ") 
  
  sendQuery <- dbSendQuery(con, select_period_with_intervention_query )
  #  hive_data <<- dbFetch(sendQuery) 
  hive_data <- dbFetch(sendQuery) 
  hive_data$hive_observation_time_local <- strptime(hive_data$hive_observation_time_local, format = "%Y-%m-%d %H:%M:%S") #  Convert string to be recognized as date
  return (hive_data)  
}

import_hive_data_csv <- function(filename){
  hive_data <- read.table(file=filename, sep=",")
  hive_data <- hive_data[ c("V1", "V2")] 
  colnames(hive_data) <- c("hive_observation_time_local", "hive_weight_kgs")
  hive_data$hive_observation_time_local <- strptime(hive_data$hive_observation_time_local, format = "%Y-%m-%d %H:%M:%S") #  Convert string to be recognized as date
  return (hive_data)  
}

extract_rows_given_weightdelta <- function(hive_data, weightdelta){
  hive_data <- hive_data %>%  mutate(weight_delta = hive_weight_kgs -
                                       dplyr::lag(hive_weight_kgs)) %>%
    mutate(weight_delta = ifelse(is.na(weight_delta), 0, weight_delta))
  
  hive_data[which(abs(hive_data[,"weight_delta"]) > weightdelta), 
            c("hive_observation_time_local", "weight_delta")]
}

extract_rows_given_timedelta <- function(hive_data, timedelta){
  hive_data <- hive_data %>%  mutate(timestamp_delta = hive_observation_time_local -
                                       dplyr::lag(hive_observation_time_local)) %>% 
    mutate(timestamp_delta = ifelse(is.na(timestamp_delta), 0, timestamp_delta))
  hive_data[which(abs(hive_data[,"timestamp_delta"]) > timedelta), 
            c("hive_observation_time_local", "timestamp_delta")]
}

plot_time_weight <- function(hive_data, title){
  if(missing(title)){
    title <- "Vægtudvikling"
  }
  min <- as.Date(head(hive_data, 1)[,"hive_observation_time_local"])
  max <- as.Date(tail(hive_data, 1)[,"hive_observation_time_local"])   
  plot(hive_data$hive_observation_time_local, hive_data$hive_weight_kgs, type = 'l', xlab = paste("Tid fra", min, "til", max, sep= " ") , ylab="Vægt", main=title)
  # , at=seq(as.Date(min),as.Date(max),by=(13*7))
}

plot_time_weight_temp <- function(hive_data){
  min <- as.Date(head(hive_data, 1)[,4])
  max <- as.Date(tail(hive_data, 1)[,4])
  par(mar = c(5, 5, 3, 5))
  plot(hive_data$hive_observation_time_local, hive_data$hive_weight_kgs, type ="l", ylab = "Vægt",
       main ="Sammenhæng mellem vægt og temperatur", xlab = paste("Tid fra", min, "til", max, sep= " "),
       col = "blue")
  par(new = TRUE)
  plot(hive_data$hive_observation_time_local, hive_data$ambient_temp_c, type = "l", xaxt = "n", yaxt = "n",
       ylab = "", xlab = "", col = "red") # , lty = 2
  axis(side = 4)
  mtext("Temperatur", side = 4, line = 3)
  legend("topleft", c("Vægt", "Temperatur"),
         col = c("blue", "red"), lty = c(1, 1))
}


manipulate_weight_deltas <- function(hive_data, periods){
  library(dplyr)
  # Add column weight_delta
  hive_data <- hive_data %>%  mutate(weight_delta = hive_weight_kgs - dplyr::lag(hive_weight_kgs)) %>%
  mutate(weight_delta = ifelse(is.na(weight_delta), 0, weight_delta))
  
  # Manipulate weight deltas
  for(row in 1:nrow(periods)){
    hive_data$weight_delta[hive_data$hive_observation_time_local> periods[row, "from"]  & hive_data$hive_observation_time_local < periods[row, "to"]  ] <- periods[row, "new_delta"]
  }
  
  # Produce cumulative sums of weight deltas
  hive_data <- hive_data %>% mutate(cum_delta=cumsum(weight_delta))
  
  # Produce new hive_weight_kgs from calculated cumukatiuve sums
  hive_data <- hive_data %>% mutate(hive_weight_kgs = hive_weight_kgs[1]+ cum_delta)
  
  
  # Remove the produced columns
  drops <- c("weight_delta", "cum_delta")
  hive_data <- hive_data[ , !(names(hive_data) %in% drops)]
  return(hive_data)
}

extract_midnight_weights <- function(hive_data){
  
  hive_data <- hive_data %>% 
    mutate( dt = as.Date(hive_observation_time_local)) %>% 
    group_by(dt) %>%
    filter(hive_observation_time_local == min(hive_observation_time_local)) %>%
    ungroup() %>%
    select(!dt)
  
  return(data.frame(hive_data))
  
}

return_period <- function(hive_data, from ,to){
  from <-  strptime(from, format = "%Y-%m-%d %H:%M:%S")
  to <- strptime(to, format = "%Y-%m-%d %H:%M:%S")
  return(hive_data[hive_data$hive_observation_time_local > from & hive_data$hive_observation_time_local < to  , ])
}

```



